{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in cleaned movie data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('resources/movie_dataset_us.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>actor_1_name</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>actor_3_name</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>rating</th>\n",
       "      <th>G</th>\n",
       "      <th>Other</th>\n",
       "      <th>PG</th>\n",
       "      <th>PG-13</th>\n",
       "      <th>R</th>\n",
       "      <th>yr_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>1144337</td>\n",
       "      <td>106759</td>\n",
       "      <td>Joseph Gordon-Levitt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>164000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>462.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>Samantha Morton</td>\n",
       "      <td>640.0</td>\n",
       "      <td>73058679.0</td>\n",
       "      <td>Daryl Sabara</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>212204</td>\n",
       "      <td>1873</td>\n",
       "      <td>Polly Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>263700000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>24000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>392.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>James Franco</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>336530303.0</td>\n",
       "      <td>J.K. Simmons</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>383056</td>\n",
       "      <td>46055</td>\n",
       "      <td>Kirsten Dunst</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>258000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>324.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>Donna Murphy</td>\n",
       "      <td>799.0</td>\n",
       "      <td>200807262.0</td>\n",
       "      <td>Brad Garrett</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>294810</td>\n",
       "      <td>2036</td>\n",
       "      <td>M.C. Gainey</td>\n",
       "      <td>1.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG</td>\n",
       "      <td>260000000.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>29000</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>635.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>Robert Downey Jr.</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>458991599.0</td>\n",
       "      <td>Chris Hemsworth</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>462669</td>\n",
       "      <td>92000</td>\n",
       "      <td>Scarlett Johansson</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>118000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_critic_for_reviews  duration  director_facebook_likes  \\\n",
       "3                   813.0     164.0                  22000.0   \n",
       "5                   462.0     132.0                    475.0   \n",
       "6                   392.0     156.0                      0.0   \n",
       "7                   324.0     100.0                     15.0   \n",
       "8                   635.0     141.0                      0.0   \n",
       "\n",
       "   actor_3_facebook_likes       actor_2_name  actor_1_facebook_likes  \\\n",
       "3                 23000.0     Christian Bale                 27000.0   \n",
       "5                   530.0    Samantha Morton                   640.0   \n",
       "6                  4000.0       James Franco                 24000.0   \n",
       "7                   284.0       Donna Murphy                   799.0   \n",
       "8                 19000.0  Robert Downey Jr.                 26000.0   \n",
       "\n",
       "         gross     actor_1_name               movie_title  num_voted_users  \\\n",
       "3  448130642.0        Tom Hardy    The Dark Knight Rises           1144337   \n",
       "5   73058679.0     Daryl Sabara              John Carter            212204   \n",
       "6  336530303.0     J.K. Simmons             Spider-Man 3            383056   \n",
       "7  200807262.0     Brad Garrett                  Tangled            294810   \n",
       "8  458991599.0  Chris Hemsworth  Avengers: Age of Ultron            462669   \n",
       "\n",
       "   cast_total_facebook_likes          actor_3_name  facenumber_in_poster  \\\n",
       "3                     106759  Joseph Gordon-Levitt                   0.0   \n",
       "5                       1873          Polly Walker                   1.0   \n",
       "6                      46055         Kirsten Dunst                   0.0   \n",
       "7                       2036           M.C. Gainey                   1.0   \n",
       "8                      92000    Scarlett Johansson                   4.0   \n",
       "\n",
       "   num_user_for_reviews language country content_rating       budget  \\\n",
       "3                2701.0  English     USA          PG-13  250000000.0   \n",
       "5                 738.0  English     USA          PG-13  263700000.0   \n",
       "6                1902.0  English     USA          PG-13  258000000.0   \n",
       "7                 387.0  English     USA             PG  260000000.0   \n",
       "8                1117.0  English     USA          PG-13  250000000.0   \n",
       "\n",
       "   title_year  actor_2_facebook_likes  imdb_score  movie_facebook_likes  \\\n",
       "3      2012.0                 23000.0         8.5                164000   \n",
       "5      2012.0                   632.0         6.6                 24000   \n",
       "6      2007.0                 11000.0         6.2                     0   \n",
       "7      2010.0                   553.0         7.8                 29000   \n",
       "8      2015.0                 21000.0         7.5                118000   \n",
       "\n",
       "  rating  G  Other  PG  PG-13  R  yr_old  \n",
       "3  PG-13  0      0   0      1  0     4.0  \n",
       "5  PG-13  0      0   0      1  0     4.0  \n",
       "6  PG-13  0      0   0      1  0     9.0  \n",
       "7     PG  0      0   1      0  0     6.0  \n",
       "8  PG-13  0      0   0      1  0     1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>G</th>\n",
       "      <th>Other</th>\n",
       "      <th>PG</th>\n",
       "      <th>PG-13</th>\n",
       "      <th>R</th>\n",
       "      <th>yr_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2329.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2.331000e+03</td>\n",
       "      <td>2.331000e+03</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2.331000e+03</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>189.291291</td>\n",
       "      <td>108.774678</td>\n",
       "      <td>807.211497</td>\n",
       "      <td>924.106913</td>\n",
       "      <td>8606.373659</td>\n",
       "      <td>6.102801e+07</td>\n",
       "      <td>1.118510e+05</td>\n",
       "      <td>13083.356070</td>\n",
       "      <td>1.491613</td>\n",
       "      <td>364.394680</td>\n",
       "      <td>4.777481e+07</td>\n",
       "      <td>2006.498927</td>\n",
       "      <td>2393.306009</td>\n",
       "      <td>6.313814</td>\n",
       "      <td>11110.499356</td>\n",
       "      <td>0.023595</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.156585</td>\n",
       "      <td>0.421278</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>9.501073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>125.561751</td>\n",
       "      <td>19.585778</td>\n",
       "      <td>3159.106858</td>\n",
       "      <td>2137.893524</td>\n",
       "      <td>11841.083376</td>\n",
       "      <td>6.886835e+07</td>\n",
       "      <td>1.455573e+05</td>\n",
       "      <td>16971.106078</td>\n",
       "      <td>2.268649</td>\n",
       "      <td>411.241536</td>\n",
       "      <td>4.516566e+07</td>\n",
       "      <td>5.395943</td>\n",
       "      <td>5146.078168</td>\n",
       "      <td>1.048771</td>\n",
       "      <td>23796.059119</td>\n",
       "      <td>0.151816</td>\n",
       "      <td>0.041398</td>\n",
       "      <td>0.363487</td>\n",
       "      <td>0.493870</td>\n",
       "      <td>0.489344</td>\n",
       "      <td>5.395943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.506998e+06</td>\n",
       "      <td>5.360000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>875.500000</td>\n",
       "      <td>1.609323e+07</td>\n",
       "      <td>2.546350e+04</td>\n",
       "      <td>2540.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1.600000e+07</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>484.250000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>503.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>3.775293e+07</td>\n",
       "      <td>6.051600e+04</td>\n",
       "      <td>5349.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>3.500000e+07</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>7.802039e+07</td>\n",
       "      <td>1.410770e+05</td>\n",
       "      <td>18395.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>447.500000</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>813.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>164000.000000</td>\n",
       "      <td>4.745447e+08</td>\n",
       "      <td>1.468200e+06</td>\n",
       "      <td>303717.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>3646.000000</td>\n",
       "      <td>2.637000e+08</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>137000.000000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>349000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_critic_for_reviews     duration  director_facebook_likes  \\\n",
       "count             2331.000000  2330.000000              2331.000000   \n",
       "mean               189.291291   108.774678               807.211497   \n",
       "std                125.561751    19.585778              3159.106858   \n",
       "min                  4.000000    46.000000                 0.000000   \n",
       "25%                 98.000000    95.000000                13.000000   \n",
       "50%                159.000000   105.500000                65.000000   \n",
       "75%                249.000000   119.000000               221.000000   \n",
       "max                813.000000   280.000000             23000.000000   \n",
       "\n",
       "       actor_3_facebook_likes  actor_1_facebook_likes         gross  \\\n",
       "count             2329.000000             2331.000000  2.331000e+03   \n",
       "mean               924.106913             8606.373659  6.102801e+07   \n",
       "std               2137.893524            11841.083376  6.886835e+07   \n",
       "min                  0.000000                0.000000  1.506998e+06   \n",
       "25%                263.000000              875.500000  1.609323e+07   \n",
       "50%                503.000000             2000.000000  3.775293e+07   \n",
       "75%                756.000000            14000.000000  7.802039e+07   \n",
       "max              23000.000000           164000.000000  4.745447e+08   \n",
       "\n",
       "       num_voted_users  cast_total_facebook_likes  facenumber_in_poster  \\\n",
       "count     2.331000e+03                2331.000000           2325.000000   \n",
       "mean      1.118510e+05               13083.356070              1.491613   \n",
       "std       1.455573e+05               16971.106078              2.268649   \n",
       "min       5.360000e+02                   0.000000              0.000000   \n",
       "25%       2.546350e+04                2540.000000              0.000000   \n",
       "50%       6.051600e+04                5349.000000              1.000000   \n",
       "75%       1.410770e+05               18395.500000              2.000000   \n",
       "max       1.468200e+06              303717.000000             43.000000   \n",
       "\n",
       "       num_user_for_reviews        budget   title_year  \\\n",
       "count           2331.000000  2.331000e+03  2331.000000   \n",
       "mean             364.394680  4.777481e+07  2006.498927   \n",
       "std              411.241536  4.516566e+07     5.395943   \n",
       "min                8.000000  1.500000e+04  1997.000000   \n",
       "25%              129.000000  1.600000e+07  2002.000000   \n",
       "50%              235.000000  3.500000e+07  2007.000000   \n",
       "75%              447.500000  6.000000e+07  2011.000000   \n",
       "max             3646.000000  2.637000e+08  2016.000000   \n",
       "\n",
       "       actor_2_facebook_likes   imdb_score  movie_facebook_likes            G  \\\n",
       "count             2330.000000  2331.000000           2331.000000  2331.000000   \n",
       "mean              2393.306009     6.313814          11110.499356     0.023595   \n",
       "std               5146.078168     1.048771          23796.059119     0.151816   \n",
       "min                  0.000000     1.600000              0.000000     0.000000   \n",
       "25%                484.250000     5.700000              0.000000     0.000000   \n",
       "50%                787.000000     6.400000            352.000000     0.000000   \n",
       "75%               1000.000000     7.000000          14000.000000     0.000000   \n",
       "max             137000.000000     8.900000         349000.000000     1.000000   \n",
       "\n",
       "             Other           PG        PG-13            R       yr_old  \n",
       "count  2331.000000  2331.000000  2331.000000  2331.000000  2331.000000  \n",
       "mean      0.001716     0.156585     0.421278     0.396825     9.501073  \n",
       "std       0.041398     0.363487     0.493870     0.489344     5.395943  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     5.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     9.000000  \n",
       "75%       0.000000     0.000000     1.000000     1.000000    14.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000    19.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.dropna(subset=['duration'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['budget', 'duration','actor_1_facebook_likes','cast_total_facebook_likes','G', 'Other', 'PG', 'PG-13', 'R',\n",
    "       'yr_old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = movie_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = movie_df['gross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>duration</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>G</th>\n",
       "      <th>Other</th>\n",
       "      <th>PG</th>\n",
       "      <th>PG-13</th>\n",
       "      <th>R</th>\n",
       "      <th>yr_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.330000e+03</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "      <td>2330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.777943e+07</td>\n",
       "      <td>108.774678</td>\n",
       "      <td>8609.761373</td>\n",
       "      <td>13087.624893</td>\n",
       "      <td>0.023605</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.156652</td>\n",
       "      <td>0.421459</td>\n",
       "      <td>0.396567</td>\n",
       "      <td>9.502575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.517481e+07</td>\n",
       "      <td>19.585778</td>\n",
       "      <td>11842.495278</td>\n",
       "      <td>16973.497340</td>\n",
       "      <td>0.151848</td>\n",
       "      <td>0.041407</td>\n",
       "      <td>0.363551</td>\n",
       "      <td>0.493899</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>5.396613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.600000e+07</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>2538.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000e+07</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>5360.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>18432.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.637000e+08</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>164000.000000</td>\n",
       "      <td>303717.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             budget     duration  actor_1_facebook_likes  \\\n",
       "count  2.330000e+03  2330.000000             2330.000000   \n",
       "mean   4.777943e+07   108.774678             8609.761373   \n",
       "std    4.517481e+07    19.585778            11842.495278   \n",
       "min    1.500000e+04    46.000000                0.000000   \n",
       "25%    1.600000e+07    95.000000              876.000000   \n",
       "50%    3.500000e+07   105.500000             2000.000000   \n",
       "75%    6.000000e+07   119.000000            14000.000000   \n",
       "max    2.637000e+08   280.000000           164000.000000   \n",
       "\n",
       "       cast_total_facebook_likes            G        Other           PG  \\\n",
       "count                2330.000000  2330.000000  2330.000000  2330.000000   \n",
       "mean                13087.624893     0.023605     0.001717     0.156652   \n",
       "std                 16973.497340     0.151848     0.041407     0.363551   \n",
       "min                     0.000000     0.000000     0.000000     0.000000   \n",
       "25%                  2538.500000     0.000000     0.000000     0.000000   \n",
       "50%                  5360.000000     0.000000     0.000000     0.000000   \n",
       "75%                 18432.250000     0.000000     0.000000     0.000000   \n",
       "max                303717.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             PG-13            R       yr_old  \n",
       "count  2330.000000  2330.000000  2330.000000  \n",
       "mean      0.421459     0.396567     9.502575  \n",
       "std       0.493899     0.489290     5.396613  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     5.000000  \n",
       "50%       0.000000     0.000000     9.000000  \n",
       "75%       1.000000     1.000000    14.000000  \n",
       "max       1.000000     1.000000    19.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9536181.280033104\n",
      "[ 8.77367486e-01  2.55314894e+05 -1.65290566e+03  1.52164889e+03\n",
      "  2.62069791e+07 -1.72059780e+07  3.39280130e+06 -3.03743821e+06\n",
      " -9.35636415e+06 -9.64251308e+04]\n",
      "R^2:  0.47681414404831324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#instantiate a linear regression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(df_features, target)\n",
    "\n",
    "#access output\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)\n",
    "print(\"R^2: \", lm.score(df_features, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>duration</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>G</th>\n",
       "      <th>Other</th>\n",
       "      <th>PG</th>\n",
       "      <th>PG-13</th>\n",
       "      <th>R</th>\n",
       "      <th>yr_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>106759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>263700000.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>258000000.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>46055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260000000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>2036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250000000.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>92000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>250000000.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>24450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>209000000.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>29991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>225000000.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>48486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>215000000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>45757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>225000000.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>20495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>225000000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>22697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>250000000.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>54083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>225000000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>12572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>230000000.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>28489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>3244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>225000000.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>9152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>180000000.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>24106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>250000000.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>64798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>209000000.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>26679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>43388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>30426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>79957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>14863</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>3218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>210000000.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>3988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>215000000.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>73441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>28631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>170000000.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>25550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>17657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>2563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>53575683.2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>135000000.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>12000000.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>215000000.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>73441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>3950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>35000000.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>1026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>1750211.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>36998505.3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>2638</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>45000000.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>15765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>34983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>77000.0</td>\n",
       "      <td>77046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>30000000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>18469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>1144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>125000.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>55784951.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>15000000.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>3861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>35000000.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2330 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           budget  duration  actor_1_facebook_likes  \\\n",
       "3     250000000.0     164.0                 27000.0   \n",
       "5     263700000.0     132.0                   640.0   \n",
       "6     258000000.0     156.0                 24000.0   \n",
       "7     260000000.0     100.0                   799.0   \n",
       "8     250000000.0     141.0                 26000.0   \n",
       "10    250000000.0     183.0                 15000.0   \n",
       "11    209000000.0     169.0                 18000.0   \n",
       "13    225000000.0     151.0                 40000.0   \n",
       "14    215000000.0     150.0                 40000.0   \n",
       "15    225000000.0     143.0                 15000.0   \n",
       "16    225000000.0     150.0                 22000.0   \n",
       "18    250000000.0     136.0                 40000.0   \n",
       "19    225000000.0     106.0                 10000.0   \n",
       "21    230000000.0     153.0                 15000.0   \n",
       "22    200000000.0     156.0                   891.0   \n",
       "23    225000000.0     186.0                  5000.0   \n",
       "24    180000000.0     113.0                 16000.0   \n",
       "27    250000000.0     147.0                 21000.0   \n",
       "28    209000000.0     131.0                 14000.0   \n",
       "31    200000000.0     135.0                 24000.0   \n",
       "32    200000000.0     195.0                 21000.0   \n",
       "33    200000000.0     108.0                 40000.0   \n",
       "35    200000000.0     104.0                 12000.0   \n",
       "36    200000000.0     150.0                   894.0   \n",
       "37    210000000.0     165.0                   974.0   \n",
       "38    215000000.0     130.0                 44000.0   \n",
       "39    200000000.0     142.0                 15000.0   \n",
       "40    170000000.0     125.0                 12000.0   \n",
       "41    200000000.0     106.0                  1000.0   \n",
       "42    200000000.0     123.0                 16000.0   \n",
       "...           ...       ...                     ...   \n",
       "4730     500000.0      89.0                 22000.0   \n",
       "4731    1000000.0     120.0                   984.0   \n",
       "4732   53575683.2      94.0                   196.0   \n",
       "4733     500000.0     108.0                    54.0   \n",
       "4752  135000000.0      94.0                 17000.0   \n",
       "4769   12000000.0      93.0                  1000.0   \n",
       "4778  215000000.0     130.0                 44000.0   \n",
       "4791     400000.0      92.0                   970.0   \n",
       "4793      15000.0      84.0                   189.0   \n",
       "4796     400000.0      90.0                   231.0   \n",
       "4804   35000000.0     101.0                   642.0   \n",
       "4816    1750211.0      88.0                    15.0   \n",
       "4826   36998505.3     112.0                   786.0   \n",
       "4830     300000.0      80.0                  1000.0   \n",
       "4842   45000000.0     133.0                  5000.0   \n",
       "4852     250000.0     113.0                 13000.0   \n",
       "4853     250000.0      91.0                   400.0   \n",
       "4855     250000.0      98.0                    94.0   \n",
       "4864     250000.0      90.0                 34000.0   \n",
       "4900     200000.0     101.0                 77000.0   \n",
       "4905   30000000.0     106.0                 17000.0   \n",
       "4930     150000.0      78.0                   376.0   \n",
       "4947     125000.0      90.0                   830.0   \n",
       "4955     100000.0     111.0                   589.0   \n",
       "4956     100000.0      81.0                   220.0   \n",
       "4960   55784951.6     100.0                  1000.0   \n",
       "4971   15000000.0     114.0                   956.0   \n",
       "4973      60000.0      84.0                  1000.0   \n",
       "4977      65000.0     100.0                     0.0   \n",
       "5012   35000000.0     109.0                  1000.0   \n",
       "\n",
       "      cast_total_facebook_likes  G  Other  PG  PG-13  R  yr_old  \n",
       "3                        106759  0      0   0      1  0     4.0  \n",
       "5                          1873  0      0   0      1  0     4.0  \n",
       "6                         46055  0      0   0      1  0     9.0  \n",
       "7                          2036  0      0   1      0  0     6.0  \n",
       "8                         92000  0      0   0      1  0     1.0  \n",
       "10                        24450  0      0   0      1  0     0.0  \n",
       "11                        29991  0      0   0      1  0    10.0  \n",
       "13                        48486  0      0   0      1  0    10.0  \n",
       "14                        45757  0      0   0      1  0     3.0  \n",
       "15                        20495  0      0   0      1  0     3.0  \n",
       "16                        22697  0      0   1      0  0     8.0  \n",
       "18                        54083  0      0   0      1  0     5.0  \n",
       "19                        12572  0      0   0      1  0     4.0  \n",
       "21                        28489  0      0   0      1  0     4.0  \n",
       "22                         3244  0      0   0      1  0     6.0  \n",
       "23                         9152  0      0   0      1  0     3.0  \n",
       "24                        24106  0      0   0      1  0     9.0  \n",
       "27                        64798  0      0   0      1  0     0.0  \n",
       "28                        26679  0      0   0      1  0     4.0  \n",
       "31                        43388  0      0   0      1  0    12.0  \n",
       "32                        30426  0      0   0      1  0     3.0  \n",
       "33                        79957  0      0   1      0  0     6.0  \n",
       "35                        14863  1      0   0      0  0     3.0  \n",
       "36                         3218  0      0   0      1  0     7.0  \n",
       "37                         3988  0      0   0      1  0     2.0  \n",
       "38                        73441  0      0   1      0  0     3.0  \n",
       "39                        28631  0      0   0      1  0     2.0  \n",
       "40                        25550  0      0   1      0  0     6.0  \n",
       "41                         4482  1      0   0      0  0     5.0  \n",
       "42                        17657  0      0   0      1  0     5.0  \n",
       "...                         ... ..    ...  ..    ... ..     ...  \n",
       "4730                      24419  0      0   0      0  1    13.0  \n",
       "4731                       2563  0      0   0      1  0     7.0  \n",
       "4732                        382  0      0   1      0  0    10.0  \n",
       "4733                        194  0      0   0      0  1    17.0  \n",
       "4752                      17883  0      0   1      0  0     1.0  \n",
       "4769                       1531  0      0   0      1  0    14.0  \n",
       "4778                      73441  0      0   1      0  0     3.0  \n",
       "4791                       3950  0      0   1      0  0    12.0  \n",
       "4793                        330  0      0   0      0  1     9.0  \n",
       "4796                        771  0      0   0      0  1    10.0  \n",
       "4804                       1026  0      0   0      1  0     8.0  \n",
       "4816                         15  0      0   0      0  1    11.0  \n",
       "4826                       2638  0      0   0      0  1    13.0  \n",
       "4830                       3010  0      0   0      1  0    13.0  \n",
       "4842                       5405  0      0   0      1  0     9.0  \n",
       "4852                      15765  0      0   0      0  1    19.0  \n",
       "4853                       1330  0      0   0      0  1    15.0  \n",
       "4855                        139  0      0   0      0  1    14.0  \n",
       "4864                      34983  0      0   0      1  0     5.0  \n",
       "4900                      77046  0      0   0      1  0     6.0  \n",
       "4905                      18469  0      0   0      0  1     3.0  \n",
       "4930                       1144  0      0   0      1  0    16.0  \n",
       "4947                        973  0      0   0      0  1     5.0  \n",
       "4955                        916  0      0   1      0  0    10.0  \n",
       "4956                        276  0      0   0      0  1     1.0  \n",
       "4960                       2283  0      0   0      1  0    18.0  \n",
       "4971                       3861  0      0   0      0  1     7.0  \n",
       "4973                       2065  0      0   0      0  1    18.0  \n",
       "4977                          0  0      0   1      0  0    12.0  \n",
       "5012                       1458  0      0   0      0  1     2.0  \n",
       "\n",
       "[2330 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a polynomial feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['budget^2'] = df['budget']**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a interaction feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['budget_R'] = df['budget']*df['R']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SKlearn to create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_data = poly.fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_columns = poly.get_feature_names(df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly = pd.DataFrame(poly_data, columns=poly_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>duration</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>G</th>\n",
       "      <th>Other</th>\n",
       "      <th>PG</th>\n",
       "      <th>PG-13</th>\n",
       "      <th>R</th>\n",
       "      <th>yr_old</th>\n",
       "      <th>budget^2</th>\n",
       "      <th>budget duration</th>\n",
       "      <th>budget actor_1_facebook_likes</th>\n",
       "      <th>budget cast_total_facebook_likes</th>\n",
       "      <th>budget G</th>\n",
       "      <th>budget Other</th>\n",
       "      <th>budget PG</th>\n",
       "      <th>budget PG-13</th>\n",
       "      <th>budget R</th>\n",
       "      <th>budget yr_old</th>\n",
       "      <th>duration^2</th>\n",
       "      <th>duration actor_1_facebook_likes</th>\n",
       "      <th>duration cast_total_facebook_likes</th>\n",
       "      <th>duration G</th>\n",
       "      <th>duration Other</th>\n",
       "      <th>duration PG</th>\n",
       "      <th>duration PG-13</th>\n",
       "      <th>duration R</th>\n",
       "      <th>duration yr_old</th>\n",
       "      <th>actor_1_facebook_likes^2</th>\n",
       "      <th>actor_1_facebook_likes cast_total_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes G</th>\n",
       "      <th>actor_1_facebook_likes Other</th>\n",
       "      <th>actor_1_facebook_likes PG</th>\n",
       "      <th>actor_1_facebook_likes PG-13</th>\n",
       "      <th>actor_1_facebook_likes R</th>\n",
       "      <th>actor_1_facebook_likes yr_old</th>\n",
       "      <th>cast_total_facebook_likes^2</th>\n",
       "      <th>cast_total_facebook_likes G</th>\n",
       "      <th>cast_total_facebook_likes Other</th>\n",
       "      <th>cast_total_facebook_likes PG</th>\n",
       "      <th>cast_total_facebook_likes PG-13</th>\n",
       "      <th>cast_total_facebook_likes R</th>\n",
       "      <th>cast_total_facebook_likes yr_old</th>\n",
       "      <th>G^2</th>\n",
       "      <th>G Other</th>\n",
       "      <th>G PG</th>\n",
       "      <th>G PG-13</th>\n",
       "      <th>G R</th>\n",
       "      <th>G yr_old</th>\n",
       "      <th>Other^2</th>\n",
       "      <th>Other PG</th>\n",
       "      <th>Other PG-13</th>\n",
       "      <th>Other R</th>\n",
       "      <th>Other yr_old</th>\n",
       "      <th>PG^2</th>\n",
       "      <th>PG PG-13</th>\n",
       "      <th>PG R</th>\n",
       "      <th>PG yr_old</th>\n",
       "      <th>PG-13^2</th>\n",
       "      <th>PG-13 R</th>\n",
       "      <th>PG-13 yr_old</th>\n",
       "      <th>R^2</th>\n",
       "      <th>R yr_old</th>\n",
       "      <th>yr_old^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000000.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>106759.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.250000e+16</td>\n",
       "      <td>4.100000e+10</td>\n",
       "      <td>6.750000e+12</td>\n",
       "      <td>2.668975e+13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>26896.0</td>\n",
       "      <td>4428000.0</td>\n",
       "      <td>17508476.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>729000000.0</td>\n",
       "      <td>2.882493e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>1.139748e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106759.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>427036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263700000.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.953769e+16</td>\n",
       "      <td>3.480840e+10</td>\n",
       "      <td>1.687680e+11</td>\n",
       "      <td>4.939101e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263700000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.054800e+09</td>\n",
       "      <td>17424.0</td>\n",
       "      <td>84480.0</td>\n",
       "      <td>247236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>409600.0</td>\n",
       "      <td>1.198720e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2560.0</td>\n",
       "      <td>3.508129e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7492.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258000000.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>46055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.656400e+16</td>\n",
       "      <td>4.024800e+10</td>\n",
       "      <td>6.192000e+12</td>\n",
       "      <td>1.188219e+13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.322000e+09</td>\n",
       "      <td>24336.0</td>\n",
       "      <td>3744000.0</td>\n",
       "      <td>7184580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>576000000.0</td>\n",
       "      <td>1.105320e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216000.0</td>\n",
       "      <td>2.121063e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260000000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.760000e+16</td>\n",
       "      <td>2.600000e+10</td>\n",
       "      <td>2.077400e+11</td>\n",
       "      <td>5.293600e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.560000e+09</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>79900.0</td>\n",
       "      <td>203600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>638401.0</td>\n",
       "      <td>1.626764e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4794.0</td>\n",
       "      <td>4.145296e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000000.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.250000e+16</td>\n",
       "      <td>3.525000e+10</td>\n",
       "      <td>6.500000e+12</td>\n",
       "      <td>2.300000e+13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000e+08</td>\n",
       "      <td>19881.0</td>\n",
       "      <td>3666000.0</td>\n",
       "      <td>12972000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>676000000.0</td>\n",
       "      <td>2.392000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>8.464000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget  duration  actor_1_facebook_likes  cast_total_facebook_likes  \\\n",
       "0  250000000.0     164.0                 27000.0                   106759.0   \n",
       "1  263700000.0     132.0                   640.0                     1873.0   \n",
       "2  258000000.0     156.0                 24000.0                    46055.0   \n",
       "3  260000000.0     100.0                   799.0                     2036.0   \n",
       "4  250000000.0     141.0                 26000.0                    92000.0   \n",
       "\n",
       "     G  Other   PG  PG-13    R  yr_old      budget^2  budget duration  \\\n",
       "0  0.0    0.0  0.0    1.0  0.0     4.0  6.250000e+16     4.100000e+10   \n",
       "1  0.0    0.0  0.0    1.0  0.0     4.0  6.953769e+16     3.480840e+10   \n",
       "2  0.0    0.0  0.0    1.0  0.0     9.0  6.656400e+16     4.024800e+10   \n",
       "3  0.0    0.0  1.0    0.0  0.0     6.0  6.760000e+16     2.600000e+10   \n",
       "4  0.0    0.0  0.0    1.0  0.0     1.0  6.250000e+16     3.525000e+10   \n",
       "\n",
       "   budget actor_1_facebook_likes  budget cast_total_facebook_likes  budget G  \\\n",
       "0                   6.750000e+12                      2.668975e+13       0.0   \n",
       "1                   1.687680e+11                      4.939101e+11       0.0   \n",
       "2                   6.192000e+12                      1.188219e+13       0.0   \n",
       "3                   2.077400e+11                      5.293600e+11       0.0   \n",
       "4                   6.500000e+12                      2.300000e+13       0.0   \n",
       "\n",
       "   budget Other    budget PG  budget PG-13  budget R  budget yr_old  \\\n",
       "0           0.0          0.0   250000000.0       0.0   1.000000e+09   \n",
       "1           0.0          0.0   263700000.0       0.0   1.054800e+09   \n",
       "2           0.0          0.0   258000000.0       0.0   2.322000e+09   \n",
       "3           0.0  260000000.0           0.0       0.0   1.560000e+09   \n",
       "4           0.0          0.0   250000000.0       0.0   2.500000e+08   \n",
       "\n",
       "   duration^2  duration actor_1_facebook_likes  \\\n",
       "0     26896.0                        4428000.0   \n",
       "1     17424.0                          84480.0   \n",
       "2     24336.0                        3744000.0   \n",
       "3     10000.0                          79900.0   \n",
       "4     19881.0                        3666000.0   \n",
       "\n",
       "   duration cast_total_facebook_likes  duration G  duration Other  \\\n",
       "0                          17508476.0         0.0             0.0   \n",
       "1                            247236.0         0.0             0.0   \n",
       "2                           7184580.0         0.0             0.0   \n",
       "3                            203600.0         0.0             0.0   \n",
       "4                          12972000.0         0.0             0.0   \n",
       "\n",
       "   duration PG  duration PG-13  duration R  duration yr_old  \\\n",
       "0          0.0           164.0         0.0            656.0   \n",
       "1          0.0           132.0         0.0            528.0   \n",
       "2          0.0           156.0         0.0           1404.0   \n",
       "3        100.0             0.0         0.0            600.0   \n",
       "4          0.0           141.0         0.0            141.0   \n",
       "\n",
       "   actor_1_facebook_likes^2  actor_1_facebook_likes cast_total_facebook_likes  \\\n",
       "0               729000000.0                                      2.882493e+09   \n",
       "1                  409600.0                                      1.198720e+06   \n",
       "2               576000000.0                                      1.105320e+09   \n",
       "3                  638401.0                                      1.626764e+06   \n",
       "4               676000000.0                                      2.392000e+09   \n",
       "\n",
       "   actor_1_facebook_likes G  actor_1_facebook_likes Other  \\\n",
       "0                       0.0                           0.0   \n",
       "1                       0.0                           0.0   \n",
       "2                       0.0                           0.0   \n",
       "3                       0.0                           0.0   \n",
       "4                       0.0                           0.0   \n",
       "\n",
       "   actor_1_facebook_likes PG  actor_1_facebook_likes PG-13  \\\n",
       "0                        0.0                       27000.0   \n",
       "1                        0.0                         640.0   \n",
       "2                        0.0                       24000.0   \n",
       "3                      799.0                           0.0   \n",
       "4                        0.0                       26000.0   \n",
       "\n",
       "   actor_1_facebook_likes R  actor_1_facebook_likes yr_old  \\\n",
       "0                       0.0                       108000.0   \n",
       "1                       0.0                         2560.0   \n",
       "2                       0.0                       216000.0   \n",
       "3                       0.0                         4794.0   \n",
       "4                       0.0                        26000.0   \n",
       "\n",
       "   cast_total_facebook_likes^2  cast_total_facebook_likes G  \\\n",
       "0                 1.139748e+10                          0.0   \n",
       "1                 3.508129e+06                          0.0   \n",
       "2                 2.121063e+09                          0.0   \n",
       "3                 4.145296e+06                          0.0   \n",
       "4                 8.464000e+09                          0.0   \n",
       "\n",
       "   cast_total_facebook_likes Other  cast_total_facebook_likes PG  \\\n",
       "0                              0.0                           0.0   \n",
       "1                              0.0                           0.0   \n",
       "2                              0.0                           0.0   \n",
       "3                              0.0                        2036.0   \n",
       "4                              0.0                           0.0   \n",
       "\n",
       "   cast_total_facebook_likes PG-13  cast_total_facebook_likes R  \\\n",
       "0                         106759.0                          0.0   \n",
       "1                           1873.0                          0.0   \n",
       "2                          46055.0                          0.0   \n",
       "3                              0.0                          0.0   \n",
       "4                          92000.0                          0.0   \n",
       "\n",
       "   cast_total_facebook_likes yr_old  G^2  G Other  G PG  G PG-13  G R  \\\n",
       "0                          427036.0  0.0      0.0   0.0      0.0  0.0   \n",
       "1                            7492.0  0.0      0.0   0.0      0.0  0.0   \n",
       "2                          414495.0  0.0      0.0   0.0      0.0  0.0   \n",
       "3                           12216.0  0.0      0.0   0.0      0.0  0.0   \n",
       "4                           92000.0  0.0      0.0   0.0      0.0  0.0   \n",
       "\n",
       "   G yr_old  Other^2  Other PG  Other PG-13  Other R  Other yr_old  PG^2  \\\n",
       "0       0.0      0.0       0.0          0.0      0.0           0.0   0.0   \n",
       "1       0.0      0.0       0.0          0.0      0.0           0.0   0.0   \n",
       "2       0.0      0.0       0.0          0.0      0.0           0.0   0.0   \n",
       "3       0.0      0.0       0.0          0.0      0.0           0.0   1.0   \n",
       "4       0.0      0.0       0.0          0.0      0.0           0.0   0.0   \n",
       "\n",
       "   PG PG-13  PG R  PG yr_old  PG-13^2  PG-13 R  PG-13 yr_old  R^2  R yr_old  \\\n",
       "0       0.0   0.0        0.0      1.0      0.0           4.0  0.0       0.0   \n",
       "1       0.0   0.0        0.0      1.0      0.0           4.0  0.0       0.0   \n",
       "2       0.0   0.0        0.0      1.0      0.0           9.0  0.0       0.0   \n",
       "3       0.0   0.0        6.0      0.0      0.0           0.0  0.0       0.0   \n",
       "4       0.0   0.0        0.0      1.0      0.0           1.0  0.0       0.0   \n",
       "\n",
       "   yr_old^2  \n",
       "0      16.0  \n",
       "1      16.0  \n",
       "2      81.0  \n",
       "3      36.0  \n",
       "4       1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Assess new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.46029054652390017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#instantiate a linear regression object\n",
    "lm_2 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_2 = lm_2.fit(df_poly, target)\n",
    "\n",
    "#access output\n",
    "# print(lm_2.intercept_)\n",
    "# print(lm_2.coef_)\n",
    "print(\"R^2: \", lm_2.score(df_poly, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit third degree polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly3_data = poly_3.fit_transform(df_features)\n",
    "poly3_columns = poly_3.get_feature_names(df_features.columns)\n",
    "df_poly3 = pd.DataFrame(poly3_data, columns=poly3_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2330, 285)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.30365379316341146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#instantiate a linear regression object\n",
    "lm_3 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_3 = lm_3.fit(df_poly3, target)\n",
    "\n",
    "#access output\n",
    "# print(lm_3.intercept_)\n",
    "# print(lm_3.coef_)\n",
    "print(\"R^2: \", lm_3.score(df_poly3, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Agenda:\n",
    "- R^2 \n",
    "- Bias versus Variance\n",
    "- Train Test Split\n",
    "- Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Coefficient of Determination ($R^2$)\n",
    "\n",
    "The _coefficient of determination_, is a measure of how well the model fits the data.\n",
    "\n",
    "It is a statistic used in the context of statistical models whose main purpose is either the prediction of future outcomes or the testing of hypotheses, on the basis of other related information. It provides a measure of how well observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model\n",
    "\n",
    "$R^2$ for a model is ultimately a _relational_ notion. It's a measure of goodness of fit _relative_ to a (bad) baseline model. This bad baseline model is simply the horizontal line $y = \\mu_Y$, for dependent variable $Y$.\n",
    "\n",
    "\n",
    "$$\\text{TSS }= \\text{ESS} + \\text{RSS }$$\n",
    "\n",
    "- TSS or SST = Total Sum of Squares \n",
    "- ESS or SSE = Explained Sum of Squares\n",
    "- RSS or SSR = Residual Sum of Squares\n",
    "\n",
    "The actual calculation of $R^2$ is: <br/> $$\\Large R^2= \\frac{\\Sigma_i(\\bar{y} - \\hat{y}_i)^2}{\\Sigma_i(y_i - \\bar{y})^2}=1- \\frac{\\Sigma_i(y_i - \\hat{y}_i)^2}{\\Sigma_i(y_i - \\bar{y})^2}$$.\n",
    "\n",
    "$R^2$ takes values between 0 and 1.\n",
    "\n",
    "$R^2$ is a measure of how much variation in the dependent variable your model explains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://pbs.twimg.com/media/D-Gu7E0WsAANhLY.png' width =\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is the Adjusted R-squared?\n",
    "\n",
    "The adjusted R-squared compares the explanatory power of regression models that contain different numbers of predictors.\n",
    "\n",
    "Suppose you compare a five-predictor model with a higher R-squared to a one-predictor model. Does the five predictor model have a higher R-squared because it’s better? Or is the R-squared higher because it has more predictors? Simply compare the adjusted R-squared values to find out!\n",
    "\n",
    "$$Adjusted R^2=1-\\left(\\frac{n-1}{n-p}\\right)(1-R^2)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "n = sample size   \n",
    "\n",
    "p  = the number of independent variables in the regression equation\n",
    "\n",
    "\n",
    "- The adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model. \n",
    "\n",
    "- The adjusted R-squared increases only if the new term improves the model more than would be expected by chance. It decreases when a predictor improves the model by less than expected by chance. \n",
    "\n",
    "- It is always lower than the R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Model Selection\n",
    "Probabilistic model selection (or “information criteria”) provides an analytical technique for scoring and choosing among candidate models.\n",
    "\n",
    "Models are scored both on their performance on the training dataset and based on the complexity of the model.\n",
    "\n",
    "- **Model Performance:** How well a candidate model has performed on the training dataset.\n",
    "- **Model Complexity:** How complicated the trained candidate model is after training.\n",
    "\n",
    "Model performance may be evaluated using a probabilistic framework, such as log-likelihood under the framework of maximum likelihood estimation. Model complexity may be evaluated as the number of degrees of freedom or parameters in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akaike Information Criterion vs. Bayesian Information Criterion\n",
    "\n",
    "The model with the lower AIC or BIC should be selected. \n",
    "\n",
    "Despite various subtle theoretical differences, their only difference in practice is the size of the penalty; BIC penalizes model complexity more heavily.\n",
    "\n",
    "Compared to the BIC method (below), the AIC statistic penalizes complex models less, meaning that it may put more emphasis on model performance on the training dataset, and, in turn, select more complex models.\n",
    "\n",
    "A downside of BIC is that for smaller, less representative training datasets, it is more likely to choose models that are too simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/probabilistic-model-selection-measures/\n",
    "\n",
    "https://www.methodology.psu.edu/resources/AIC-vs-BIC/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Machine Learning Process\n",
    "\n",
    "1. Look at the big picture. \n",
    "2. Get the data. \n",
    "3. Discover and visualize the data to gain insights. \n",
    "4. Prepare the data for Machine Learning algorithms. \n",
    "5. Select a model and train it. \n",
    "6. Fine-tune your model. \n",
    "7. Present your solution. \n",
    "8. Launch, monitor, and maintain your system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.kdnuggets.com/wp-content/uploads/crisp-dm-4-problems-fig1.png' width =\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**A proper machine learning workflow includes:**\n",
    "\n",
    "* Separate training and test sets\n",
    "* Trying appropriate algorithms (No Free Lunch)\n",
    "* Fitting model parameters\n",
    "* Tuning impactful hyperparameters\n",
    "* Proper performance metrics\n",
    "* Systematic cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias - Variance \n",
    "\n",
    "There are 3 types of prediction error: bias, variance, and irreducible error.\n",
    "\n",
    "\n",
    "**Total Error = Bias + Variance + Irreducible Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Bias-Variance Tradeoff\n",
    "\n",
    "\n",
    "**Let's do a thought experiment:**\n",
    "\n",
    "1. Imagine you've collected 5 different training sets for the same problem.\n",
    "2. Now imagine using one algorithm to train 5 models, one for each of your training sets.\n",
    "3. Bias vs. variance refers to the accuracy vs. consistency of the models trained by your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='resources/Bias-vs.-Variance-v5-2-darts.png' width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**High bias** algorithms tend to be less complex, with simple or rigid underlying structure.\n",
    "\n",
    "+ They train models that are consistent, but inaccurate on average.\n",
    "+ These include linear or parametric algorithms such as regression and naive Bayes.\n",
    "\n",
    "On the other hand, **high variance** algorithms tend to be more complex, with flexible underlying structure.\n",
    "\n",
    "+ They train models that are accurate on average, but inconsistent.\n",
    "+ These include non-linear or non-parametric algorithms such as decision trees and nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bias-Variance Tradeoff\n",
    "\n",
    "This tradeoff in complexity is why there's a tradeoff in bias and variance - an algorithm cannot simultaneously be more complex and less complex.\n",
    "\n",
    "**Total Error = Bias^2 + Variance + Irreducible Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<img src='resources/Bias-vs.-Variance-v4-chart.png' width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Error from Bias\n",
    "\n",
    "**Bias** is the difference between your model's expected predictions and the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='resources/noisy-sine-linear.png' width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Error from Variance\n",
    "\n",
    "**Variance** refers to your algorithm's sensitivity to specific sets of training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='resources/noisy-sine-decision-tree.png' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one is overfit and which one is underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to try to find the proper balance of variance and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='resources/noisy-sine-third-order-polynomial.png' width=500 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train Test Split\n",
    "\n",
    "**How do we know if our model is overfitting or underfitting?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If our model is not performing well on the training  data, we are probably underfitting it.  \n",
    "\n",
    "\n",
    "To know if our  model is overfitting the data, we need  to test our model on unseen data. \n",
    "We then measure our performance on the unseen data. \n",
    "\n",
    "If the model performs way worse on the  unseen data, it is probably  overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The previous module introduced the idea of dividing your data set into two subsets:\n",
    "\n",
    "* **training set** —a subset to train a model.\n",
    "* **test set**—a subset to test the trained model.\n",
    "\n",
    "You could imagine slicing the single data set as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='resources/testtrainsplit.png' width =550 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Never train on test data.** If you are seeing surprisingly good results on your evaluation metrics, it might be a sign that you are accidentally training on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src='https://developers.google.com/machine-learning/crash-course/images/WorkflowWithTestSet.svg' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Evaluation Metrics for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![alt text](resources/mae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Mean Squared Error** (MSE) is the mean of the squared errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![alt text](resources/mse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Root Mean Squared Error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![alt text](resources/rmse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MSE is more popular than MAE because MSE \"punishes\" larger errors. \n",
    "\n",
    "But, RMSE is even more popular than MSE because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "Additionally, I like to divide the RMSE by the standard deviation to  convert it to something similiar to a Z-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practicum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify my features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['budget',\n",
       " 'duration',\n",
       " 'actor_1_facebook_likes',\n",
       " 'cast_total_facebook_likes',\n",
       " 'G',\n",
       " 'Other',\n",
       " 'PG',\n",
       " 'PG-13',\n",
       " 'R',\n",
       " 'yr_old']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'duration', 'actor_1_facebook_likes',\n",
       "       'cast_total_facebook_likes', 'G', 'Other', 'PG', 'PG-13', 'R',\n",
       "       'yr_old'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Split\n",
    "\n",
    "The random state variable makes it so you can always have the same 'random' split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - Features:  (1864, 10) Target:  (1864,)\n",
      "Training set - Features:  (466, 10) Target:  (466,)\n"
     ]
    }
   ],
   "source": [
    "#improt train_test_split from sklearn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#call train_test_split on the data and capture the results\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, target, random_state=34,test_size=0.2)\n",
    "\n",
    "#check the shape of the results\n",
    "print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape)\n",
    "print(\"Training set - Features: \", X_test.shape, \"Target: \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11638661.366280936\n",
      "[ 8.81223377e-01  2.64424381e+05 -1.96995508e+03  1.89984277e+03\n",
      "  3.37968170e+07 -1.94000532e+07  1.68475422e+06 -5.18353829e+06\n",
      " -1.08979797e+07 -1.08042470e+04]\n"
     ]
    }
   ],
   "source": [
    "# fit a model\n",
    "from sklearn import linear_model\n",
    "\n",
    "#instantiate a linear regression object\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well did our model perform\n",
    "\n",
    "Previously we have looked at the R^2 of the model  to  determine  how good of a model this is.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.5026270705514394\n"
     ]
    }
   ],
   "source": [
    "print (\"R^2 Score:\", lm.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 33486346.49121705\n",
      "Mean Squared Error: 2541143374705900.0\n",
      "Root Mean Squared Error: 50409754.7574465\n"
     ]
    }
   ],
   "source": [
    "#import the metrics module from sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "train_mae = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', train_mae )\n",
    "print('Mean Squared Error:',  train_mse)\n",
    "print('Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is difficult to understand how good or bad a model is because of the scale of the data. Therefore you can divid the RMSE by the standard deviation of the target variable to transform the metric to a Z-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Score of Mean Absolute Error: 0.4862079275721459\n",
      "Z-Score of Root Mean Squared Error: 0.7319288294549147\n"
     ]
    }
   ],
   "source": [
    "price_std = target.std()\n",
    "\n",
    "print('Z-Score of Mean Absolute Error:', train_mae/price_std )\n",
    "print('Z-Score of Root Mean Squared Error:' , train_rmse/price_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predictions')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The line / model\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fde90827c88>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.residplot(y_pred, y_test, lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2909598668794977\n"
     ]
    }
   ],
   "source": [
    "print (\"Score:\", lm.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:32979236.491171956\n",
      "Mean Squared Error:2303594738404592.0\n",
      "Root Mean Squared Error:47995778.33939765\n"
     ]
    }
   ],
   "source": [
    "test_mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:' + str(metrics.mean_absolute_error(y_test, y_pred)))\n",
    "print('Mean Squared Error:' + str(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Root Mean Squared Error:' + str(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error  Z: 0.47884489971129207\n",
      "Root Mean Squared Error Z: 0.6968788883771263\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error  Z:', test_mae/price_std )\n",
    "print('Root Mean Squared Error Z:' , test_rmse/price_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our Model's performance on training data versus test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  50409754 vs. Testing:  47995778\n"
     ]
    }
   ],
   "source": [
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Polynomial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split the polynomial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c3170c2ca4ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#call train_test_split on the data and capture the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#check the shape of the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#call train_test_split on the data and capture the results\n",
    "____, ____, ____, ____ = train_test_split(____, ____, random_state=34,test_size=0.2)\n",
    "\n",
    "#check the shape of the results\n",
    "print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape)\n",
    "print(\"Training set - Features: \", X_test.shape, \"Target: \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-52d618e1fdc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#fit the linear regression to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_____\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_____' is not defined"
     ]
    }
   ],
   "source": [
    "#instantiate a linear regression object\n",
    "____ = linear_model.LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "____ = _____.fit(____, _____)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got estimator LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5c5df123629e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 170\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         raise TypeError('Expected sequence or array-like, got '\n\u001b[0;32m--> 132\u001b[0;31m                         'estimator %s' % x)\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got estimator LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)"
     ]
    }
   ],
   "source": [
    "\n",
    "____ = metrics.mean_absolute_error(____, ____)\n",
    "____ = metrics.mean_squared_error(____, ____)\n",
    "____ = np.sqrt(metrics.mean_squared_error(____, ____))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', ____ )\n",
    "print('Mean Squared Error:',  ____)\n",
    "print('Root Mean Squared Error:' , ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-4e841d7d1311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "____ = ____.predict(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got estimator LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-eeff127cfcb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m____\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Absolute Error:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 170\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         raise TypeError('Expected sequence or array-like, got '\n\u001b[0;32m--> 132\u001b[0;31m                         'estimator %s' % x)\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got estimator LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)"
     ]
    }
   ],
   "source": [
    "____ = metrics.mean_absolute_error(____, ____)\n",
    "____ = np.sqrt(metrics.mean_squared_error(____, ____))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:' + str(metrics.mean_absolute_error(____, ____)))\n",
    "print('Mean Squared Error:' + str(metrics.mean_squared_error(____, ____)))\n",
    "print('Root Mean Squared Error:' + str(np.sqrt(metrics.mean_squared_error(____, ____))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our Model's performance on training data versus test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Training: ', int(____), \"vs. Testing: \", int(____))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
